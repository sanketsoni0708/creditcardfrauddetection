{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhDqWQrYqthAG5r8uUZ+4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanketsoni0708/creditcardfrauddetection/blob/main/creditcardfrauddetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit card fraud is a term that has been coined for unauthorized access of payment cards like credit cards or debit cards to pay for using services or goods. Hackers or fraudsters may obtain the confidential details of the card from unsecured websites. When a fraudster compromises an individual's credit/debit card, everyone involved in the process suffers, right from the individual whose confidential data has been leaked to the businesses (generally banks) who issue the credit card and the merchant who is finalizing the transaction with purchase. This makes it extremely essential to identify the fraudulent transactions at the onset.\n",
        "\n",
        "A credit card is one of the most used financial products to make online purchases and payments  such as gas, groceries, TVs, traveling, shopping bills, and so on because of the non-availability of funds at that instance. Credit cards are of most value that provide various benefits in the form of points while using them for different transactions.\n",
        "\n",
        "The data is heavily imbalanced, i.e., the count of data labeled as fraudulent is way less than the data labeled as non-fraudulent data. This makes it extremely tricky to train the model as it tends to overfit for the majority class and underfit for the minority class. Techniques like oversampling, undersampling, cost-sensitive learning, etc. can be used to deal with this. The metrics used for the final model are different from standard evaluation metrics of accuracy, AUC-ROC, etc."
      ],
      "metadata": {
        "id": "NwZROcM8J5y7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afahJ-GaI7MW"
      },
      "outputs": [],
      "source": [
        "# Install and Import Dependencies\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "8325dP5OJQko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']"
      ],
      "metadata": {
        "id": "BP1CZFJZJQny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OcsGkFumJQqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to handle class imbalance in the training set\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "JCa0UwUoJQta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "82hehWgXJQwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store evaluation metrics\n",
        "results = {}"
      ],
      "metadata": {
        "id": "7l7vW6E6JQy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_resampled, y_train_resampled)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1, \"ROC-AUC\": roc_auc}\n"
      ],
      "metadata": {
        "id": "9Bbe78ElJsjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(\"Performance Comparison:\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.2f}\")\n",
        "    print(f\"Precision: {metrics['Precision']:.2f}\")\n",
        "    print(f\"Recall: {metrics['Recall']:.2f}\")\n",
        "    print(f\"F1 Score: {metrics['F1 Score']:.2f}\")\n",
        "    print(f\"ROC-AUC: {metrics['ROC-AUC']:.2f}\")"
      ],
      "metadata": {
        "id": "pm2OkeTpJsnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjMBRJ50JssC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqa0bFeAJsvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvWyC_IWJsyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFc_ZDVAJs2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}